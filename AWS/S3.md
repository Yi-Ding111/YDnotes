# S3



## Use Boto3 create bucket

[s3_client.create_bucket()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/create_bucket.html)

[s3_client.put_object()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/put_object.html)

[s3_client.put_bucket_versioning()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/put_bucket_versioning.html): Sets the versioning state of an existing bucket.

```python
import boto3

s3_client=boto3.client('s3',region_name='us-west-1')
# create a bucket
s3_client.create_bucket(Bucket='wingwing')
# enable versioning
s3_client.put_bucket_versioning(Bucket='wingwing',
                                VersioningConfiguration={'Status': 'Enabled'})
# create folder
s3_client.put_object(Bucket='wingwing',
                     Key='YD/')
```



## Use Boto3 delete bucket and objects

```python
import boto3


```









## Use python to read pkl models stored in S3 bucket

```python
import pickle
import boto3

s3=boto3.client('s3')

# Specify the bucket and object key
model_bucket='codex-strethfit-test'
model_key='final_models/xgbregressor_model_2023-05-08.pickle'

# Get the object from the bucket
response = s3.get_object(Bucket=model_bucket, Key=model_key)

# get model's data
model_data = response['Body'].read()

# load the model
model=pickle.loads(model_data)
```





## Use python to read s3 parquet file

```python
import boto3
from io import BytesIO

s3=boto3.client('s3')

external_bucket='codex-pricing-test'
CPI_key='external-data-test-YD/AU/national_external_data/cpi/cpi_2023.parquet'

response = s3.get_object(Bucket=external_bucket, Key=CPI_key)

parquet_content = response['Body'].read()

# Load the Parquet content into a Pandas DataFrame
cpi = pd.read_parquet(BytesIO(parquet_content)) # df
```

